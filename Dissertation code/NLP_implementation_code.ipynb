{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN2JdRfwboDN5+Qnm9dlNgY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Trying to find content of an article from PubMed using Key words**"],"metadata":{"id":"f32FT1hZKMaa"}},{"cell_type":"markdown","source":["The code consists of the following Task\n","\n","Identifying what is the content of article witout a scientific name of corresponding synonymn,common or pharmaceutical name.\n","This code analyses missing scientific name in an article is legit or if the artcle content is not relevant to the same by identifying the keywords"],"metadata":{"id":"3sm4zX8mSCrO"}},{"cell_type":"markdown","source":["Required Installations"],"metadata":{"id":"OVPl9j-vXGTF"}},{"cell_type":"code","source":["!pip install biopython\n","!pip install beautifulsoup4\n","!pip3 install pytextrank\n","!spacy download en_core_web_sm\n","!pip3 install wordcloud\n","!pip install matplotlib==3.1.3\n","!pip3 install keybert"],"metadata":{"id":"nW25bdjFW5GW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","import dependent libraries"],"metadata":{"id":"u231u6bTKvQn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1GC78xnoKKOH"},"outputs":[],"source":["import pandas as pd\n","import re\n","import Bio\n","import requests\n","from bs4 import BeautifulSoup\n","from Bio import Entrez\n","Entrez.email =  \"radhu.palliyana@gmail.com\" # provide mail id after creating api key"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive') "],"metadata":{"id":"OuzmFtKeeCZh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extracting article id and content of the articles related to medicinal plants for given species and genus with retrival max of 50 Ids**\n","\n","Contains code for searching a term using Esearch.\n","\n","It search for articles that talk about medicinal plants using the Esearch by giving term parameter and retreive article id.Then fectches the article content using Efetch using the corresponding article id .The text of article content is then extracted from abstract and body of article."],"metadata":{"id":"5Zf0wNiiDsJt"}},{"cell_type":"code","source":["handle = Entrez.esearch(db =\"pmc\", term= 'abelmoschi corolla',retmax= \"50\") # retrieve maximum 50 article ids containing the given term\n","rec_list = Entrez.read(handle)\n","handle.close()\n","print(rec_list['Count']) # retrieves the total number of article having the given term\n","print(len(rec_list['IdList']))\n","print(rec_list['IdList'])\n","total_id = rec_list['IdList'] #consolidating all the corresponding article Ids having the given term into a list\n","#extracting the article having the given term using each article id from the list"],"metadata":{"id":"N7h_QTX1sWhD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For eg: '9340222', '9403506', '8069016', '8037085', '7535141', '7482509', '6501976', '6500631', '6425497', '6222764', '6155732', '4926151' are the list of article corresponding to the given pharmaceutical name: abelmoschi corolla\n","\n","Among these the following article have scientific names tagged to this pharmaceutical name:  9403506,7535141 and the rest doesnt have one.\n","\n","So here for further research we take the one of the article which do not have scientific name mentioned and further investigate on the same. Article id : 8037085 is considered for the same\n","\n","To get check for each article manually navigate to and replace the PMC iD with the article id number for eg for id 9340222 :https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9340222/"],"metadata":{"id":"vIRr5d14sgW3"}},{"cell_type":"code","source":["\n","handle = Entrez.efetch(db='pmc', id = 8037085 , retmode = 'xml') #Retrieve the corresponding article using article id\n","total_content =  handle.read()\n","#print(total_content) # Prints the entire html page content of the article.This is usefull to identify the corresponding tag containing the abstract and body of the article.\n","soup = BeautifulSoup(total_content,\"html.parser\")\n","abstracts = soup.find('abstract')\n","body = soup.find('body')\n","print(abstracts)\n","#extracting the text from abstract and body of the article\n","print(\"abstract for the article id :\", id)\n","print(str(abstracts.string))\n","abstract_text = str(abstracts.string)\n","print(\"Entire content of the article id :\", id)\n","print(body.get_text())\n","body_text = body.get_text()\n"],"metadata":{"id":"gmuxMY8jYrPs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Text Rank : Using text rank extracts and summerize the text of the article body"],"metadata":{"id":"M5uTcc3VweIs"}},{"cell_type":"code","source":["import spacy\n","import pytextrank\n","# load a spaCy model\n","nlp = spacy.load(\"en_core_web_sm\")\n","# add PyTextRank to the spaCy pipeline\n","nlp.add_pipe(\"textrank\")\n","abstract_doc = nlp(body_text)\n","# examine the top-ranked phrases in the document\n","for phrase in abstract_doc._.phrases[:30]:\n","    print(phrase.text)"],"metadata":{"id":"nHx9CUPXvXOR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Word Cloud"],"metadata":{"id":"U6OoNC9ixBGe"}},{"cell_type":"code","source":["import collections\n","import numpy as np\n","import pandas as pd\n","#import matplotlib.cm as cm\n","import matplotlib.pyplot as plt\n","from matplotlib import rcParams\n","from wordcloud import WordCloud, STOPWORDS\n","\n","stopwords = STOPWORDS\n","wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\", max_words=1000).generate(body_text)\n","rcParams['figure.figsize'] = 15, 20\n","plt.imshow(wordcloud)\n","plt.axis(\"off\")\n","plt.show()"],"metadata":{"id":"GJzyDnamxDD9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Keybert is used for keyword extraction from article. It generates most similar keywords and keyphrases to a given document using BERT embedding"],"metadata":{"id":"y5loB7YG1CIJ"}},{"cell_type":"code","source":["from keybert import KeyBERT\n","kw_model = KeyBERT()\n","keywords = kw_model.extract_keywords(body_text)\n","print(\"keywords body\",keywords)\n","keywords_abstract = kw_model.extract_keywords(abstract_text)\n","print(\"keywords abstract\",keywords_abstract)"],"metadata":{"id":"B1TXtdVfymme"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Reference:**\n","Entrez is a molecular biology database system that provides integrated access to nucleotide and protein sequence.The system is produced by the National Center for Biotechnology Information (NCBI).\n","\n","Entrez Programming Utilities user guide is available at : https://www.ncbi.nlm.nih.gov/books/NBK25501/\n","\n","PyTextRank documentation: https://pypi.org/project/pytextrank/\n","\n","WordCloud documentation: https://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html\n","\n","KeyBERT documentation: https://pypi.org/project/keybert/"],"metadata":{"id":"NmVTxI8qp8gt"}}]}